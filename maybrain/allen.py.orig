# -*- coding: utf-8 -*-
"""
Created on Fri Apr 11 19:05:26 2014
Module for linking with the Allen brain atlas
@author: tim
"""

import maybrain.brainObjs as mbo

import csv
from os import path,rename
import numpy as np
from scipy import stats
from matplotlib import pyplot as plt
from glob import glob

# class allenBrain:
#     def __init__(self, allenSubj, assocMat, delim=",",
#                  spatialFile="atlas471_xyz_flip_xy.txt", nodesToExclude=None):
       
#         self.subj = allenSubj
#         self.fName = "SampleAnnot.csv"
#         self.maFile = "MicroarrayExpression.csv"
       
#         # set up brain for expression data
#         self.a = mbo.brainObj()
       
#         # import probe data
#         f = open(path.join(self.subj, self.fName), "rb")        
#         reader = csv.DictReader(f, delimiter=",", quotechar='"')
       
#         self.headers = ['probe']
#         for l in reader:
#             n = int(l["structure_id"])
#             self.a.G.add_node(n)
#             self.a.G.node[n] = l
#             self.headers.append(l["structure_id"])
#         f.close()
       
#         # convert location data for Allen brain from MNI space
#         # for n in self.a.G.nodes():
#         #     x = 45 - (float(self.a.G.node[n]['mni_x'])/2)
#         #     y = 63 + (float(self.a.G.node[n]['mni_y'])/2)
#         #     z = 36 + (float(self.a.G.node[n]['mni_z'])/2)
#         #     self.a.G.node[n]['xyz'] = (x,y,z)
#         for n in self.a.G.nodes():
#             x = float(self.a.G.node[n]['mni_x'])
#             y = float(self.a.G.node[n]['mni_y'])
#             z = float(self.a.G.node[n]['mni_z'])
#             self.a.G.node[n]['xyz'] = (x,y,z)    
       
#         # set up brain with graph properties
#         self.c = mbo.brainObj()
#         self.c.importAdjFile(assocMat, delimiter=delim,
#                              exclnodes=nodesToExclude)
#         self.c.importSpatialInfo(spatialFile)
   
#     def comparison(self):
#         # set up dictionary to link nodes from probe data and graph
#         # keys are the mri nodes and values are disctionaries containing two keys: 
#         # key 1= allen, value= (n=id of closest allen node, d=distance to closest allen node)
#         # key 2= mri, value= (n=id of closest other mri node, d=distance to closest mri node)

#         nodeDictMRIs = {}
       
#         for node in self.c.G.nodes():
#             dOther = (None, 999.) # dummy length of 999
#             dOwn = (None, 999.)
       
#             for n in self.a.G.nodes():
#                 d = np.linalg.norm(np.array(self.c.G.node[node]['xyz'] - np.array(self.a.G.node[n]['xyz'])))
#                 if d < dOther[1]:
#                     dOther = (n,d)
           
#             for n in [v for v in self.c.G.nodes() if not v==node]:
#                 d = np.linalg.norm(np.array(self.c.G.node[node]['xyz'] - np.array(self.c.G.node[n]['xyz'])))
#                 if d < dOwn[1]:
#                     dOwn = (n,d)
#             nodeDictMRIs[node] = {"allen":dOther, "MRIs":dOwn}
       
#         # set up dictionary to link nodes from probe data and graph
#         nodeDictAllen = {}
#         for node in self.a.G.nodes():
#             dOther = (None, 999.)
#             dOwn = (None, 999.)
           
#             for n in self.c.G.nodes():
#                 d = np.linalg.norm(np.array(self.a.G.node[node]['xyz'] - np.array(self.c.G.node[n]['xyz'])))
#                 if d < dOther[1]:
#                     dOther = (n,d)
           
#             for n in [v for v in self.a.G.nodes() if not v==node]:
#                 d = np.linalg.norm(np.array(self.a.G.node[node]['xyz'] - np.array(self.a.G.node[n]['xyz'])))
#                 if d < dOwn[1]:
#                     dOwn = (n,d)
#             nodeDictAllen[node] = {"allen":dOwn, "MRIs":dOther}
       
#         nodePairs = []
#         # for each MRI node
#         for node in nodeDictMRIs.keys():
#             # find closest allen node 'n'
#             n = nodeDictMRIs[node]['allen'][0]
#             self.c.G.node[node]['pair'] = n
#             self.a.G.node[n]['pair'] = node
#             nodePairs.append((node,n))
#             # if there is no other MRI node closer to the current MRI region 
#             # if nodeDictMRIs[node]['allen'][1] < nodeDictMRIs[node]['MRIs'][1]:
#             # if there is also no other MRI node closer to this allen region then match
#             #     n = nodeDictMRIs[node]['allen'][0]
#             #     if nodeDictAllen[n]['MRIs'][0] == node:
#             #         self.c.G.node[node]['pair'] = n
#             #         self.a.G.node[n]['pair'] = node
#             #         nodePairs.append((node,n))
#             #     else:
#             # if there is another MRI node closer to this allen region then delete current regions (and do not match it)
#             #         self.c.G.remove_node(node)
#             # else:
#             #     self.c.G.remove_node(node)
       
#         for node in self.a.G.nodes():
#             if not 'pair' in self.a.G.node[node].keys():
#                 self.a.G.remove_node(node)
                   
#     def doPlot(self):
#         self.a.importSkull("/usr/share/data/fsl-mni152-templates/MNI152_T1_2mm_brain.nii.gz")
#         p = mbo.plotObj()
#         p.plotSkull(self.a, contourVals = [3000,9000])
#         p.plotBrainCoords(self.c, nodes =  self.c.G.nodes(),
#                                      col=(1,0,0), sizeList=5)
#         p.plotBrainCoord(self.a, nodes = self.a.G.nodes(),
#                                      col=(0,0,1), sizeList=5)
#         self.saveFig()
                                     
#     def probeData(self, propDict, graphMetric="gm", nodeList=None, plot=False,
#                   probeList=[], probeNumbers=[], sigVal=1.0, T=False):
#         '''
       
#         '''
#         self.gm=graphMetric
#         self.sigVal=sigVal
       
#         probes = open(path.join(self.subj,"Probes.csv"), "rb")
#         probeReader = csv.DictReader(probes, delimiter=",",
#                                      quotechar='"')
#         self.probeDict = {l['probe_id']:[l['gene_symbol'], l['gene_name']] for l in probeReader}
#         if probeList:
#             probeNumbers = []
#             for p in probeList:
#                 probeNumbers.extend([v for v in self.probeDict.keys() if any([p in self.probeDict[v][1], p in self.probeDict[v][0]])])
#             print " ".join(["Probe numbers:", ' '.join(probeNumbers)])
       
#         else:
#             probeNumbers = None
       
#         self.outFile = path.join(self.subj, self.gm+'.txt')
#         if path.exists(self.outFile):
#             rename(self.outFile, self.outFile+'.old')
#         f = open(self.outFile,"w")
#         f.writelines(','.join(['probe_id', 'gene_name', 'r','p\n']))
#         f.close()

#         self.propDict = propDict
                               
#         if nodeList:
#             for node in self.c.G.nodes():
#                 if not node in nodeList:
#                     self.a.G.remove_node(self.c.G.node[node]['pair'])
#                     self.c.G.remove_node(node)
       
#         # import probe data
#         f = open(path.join(self.subj, self.maFile), "rb")
#         reader = csv.DictReader(f, delimiter=",",
#                                 fieldnames=self.headers,
#                                 quotechar='"')
       
#         for l in reader:
#             if T:
#                 self.probeSubT(l, plot, probeNumbers)
#             else:
#                 self.probeSub(l, plot, probeNumbers)
#         f.close()
   
# #    def brainProbeVis(self):
# #        
   
#     def probeSub(self, l, plot, probeNumbers=None):
#         probe = l['probe']
#         if probeNumbers:
#             if probe in probeNumbers:
#                 # assign probe values to sample numbers
#                 for node in self.a.G.nodes():
#                     if l[str(node)]:
#                         self.a.G.node[node][probe] = l[str(node)]
#                     else:
#                         self.a.G.node[node][probe] = None
               
#                 aa = np.zeros((len(self.a.G.nodes()),3))
               
#                 for n,node in enumerate(self.a.G.nodes()):
#                     if self.propDict[self.a.G.node[node]['pair']]:
#                         aa[n,0] = self.a.G.node[node][probe]
#                         aa[n,1] = self.propDict[self.a.G.node[node]['pair']]
#                         aa[n,2] = self.a.G.node[node]['pair']
#                     else:
#                         aa[n,:] = [np.nan, np.nan, np.nan]
               
#                 aa = aa[~np.isnan(aa)]
#                 aa.shape = (len(aa)/3,3)
                   
#                 r,p = stats.pearsonr(aa[:,0], aa[:,1])
               
#                 if p < self.sigVal:
#                     print probe
#                     # plot graph
#                     out = open(self.outFile, "a")
#                     out.writelines(','.join([str(v) for v in [probe, '"'+self.probeDict[probe][1]+'"', r, p]])+'\n')
#                     out.close()
#                     if plot:
#                         plt.scatter(aa[:,1], aa[:,0])
#                         plt.savefig(self.outFile.replace('.txt',probe+'.png'), dpi=300)
#                         plt.close()
                   
#                     # save data
#                     datFile = open(self.outFile.replace('.txt', probe+self.gm+'.txt'), "wb")
#                     datFile.writelines(' '.join([probe, self.gm, "node", "subj"])+'\n')
#                     datFile.writelines('\n'.join([' '.join([str(aa[n,0]), str(aa[n,1]), str(aa[n,2]), self.subj]) for n in range(len(aa[:,1]))]))
                   
#         else:
#             pass
   
#     def probeSubT(self, l, plot, probeNumbers=None):
#         '''
#         l is a line from the probe file.
#         The purpose of this function is to write thresholded data to a datafile
#         eg for use in ANOVA
#         '''
#         probe = l['probe']
#         datFile = None
#         if probeNumbers:
#             if probe in probeNumbers:
#                 # assign probe values to sample numbers
#                 for node in self.a.G.nodes():
#                     if l[str(node)]:
#                         self.a.G.node[node][probe] = l[str(node)]
#                     else:
#                         self.a.G.node[node][probe] = None
                                     
#                     outDict = {probe:probe, 'subj':self.subj}
#                     for p in self.propDict.keys():
#                         outDict[p] = self.propDict[p]
                   
#                     if not datFile:
#                         headers = [probe, "subj"]
#                         gmSubjs = self.propDict[self.probeDict.keys()[0]].keys()
#                         gmSubjs.sort()
#                         headers.extend(gmSubjs)

#                         datFile = open(self.outFile.replace('.txt', probe+self.gm+'.txt'), "wb")
#                         writer = csv.DictWriter(datFile, fieldnames=headers, delimiter=" ")
#                         writer.writeheader()
                       
#                     writer.writerow(outDict)
       
#     def norm(self,x):
#         xMin = np.min(x)
#         xMax = np.max(x)
       
#         x = np.array((x)) - xMin
#         x = (x/xMax) * 20
#         return([v for v in x])

class multiSubj:
    def __init__(self, assocMat, nodesToExclude=[], delim=" ",
                 subjList=None, spatialFile="atlas471_xyz_flip_xy.txt"):
        if subjList:
            self.subjList = subjList
        else:
            self.subjList = [v for v in glob("17823*") if path.isdir(v)]
           
        self.fName = "SampleAnnot.csv"
        self.maFile = "MicroarrayExpression.csv"
        self.probeFile = "Probes.csv"
       
        # set up brain for expression data
        self.a = mbo.brainObj()
       
        node_counter = 0

        self.headers={}
        for subj in self.subjList:
            # import probe data
            f = open(path.join(subj, self.fName), "rb")        
            reader = csv.DictReader(f, delimiter=",", quotechar='"')
           
            self.headers[subj] = ['probe']
            for l in reader:
                # n = int(l["structure_id"])
                n = node_counter # GIVE NODES UNIQUE INCREMENTAL ID (across all subjects)
                if not self.a.G.has_node(n):
                    self.a.G.add_node(n)
                    self.a.G.node[n] = l
                    node_counter += 1
                # self.headers[subj].append(l["structure_id"])
                self.headers[subj].append(l["structure_acronym"]) #STORE structure_acronym INSTEAD OF structure_id
            f.close()
           
<<<<<<< HEAD
            if MNIcoords:
                # convert location data for Allen brain from MNI space
                for n in self.a.G.nodes():
                    x = 45 - (float(self.a.G.node[n]['mni_x'])/2)
                    y = 63 + (float(self.a.G.node[n]['mni_y'])/2)
                    z = 36 + (float(self.a.G.node[n]['mni_z'])/2)
                    self.a.G.node[n]['xyz'] = (x,y,z)
            else:
                for n in self.a.G.nodes():
                    x = float(self.a.G.node[n]['mni_x'])
                    y = float(self.a.G.node[n]['mni_y'])
                    z = float(self.a.G.node[n]['mni_z'])
                    self.a.G.node[n]['xyz'] = (x,y,z)
                    
=======
            # convert location data for Allen brain from MNI space
            # for n in self.a.G.nodes():
            #     x = 45 - (float(self.a.G.node[n]['mni_x'])/2)
            #     y = 63 + (float(self.a.G.node[n]['mni_y'])/2)
            #     z = 36 + (float(self.a.G.node[n]['mni_z'])/2)
            #     self.a.G.node[n]['xyz'] = (x,y,z)
            for n in self.a.G.nodes():
                x = float(self.a.G.node[n]['mni_x'])
                y = float(self.a.G.node[n]['mni_y'])
                z = float(self.a.G.node[n]['mni_z'])
                self.a.G.node[n]['xyz'] = (x,y,z)    
        #written by PV to add symmetric data !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!     
        
        #written by PV to print location of each structure_id to file
        #print(len(self.a.G.nodes()))
        #f = open('myAllenNodes.txt', 'w') 
        #for n in self.a.G.nodes():
        #    f.write('%s, %s, %s, %s \n' % (str(n), str(self.a.G.node[n]['xyz'][0]),str(self.a.G.node[n]['xyz'][1]),str(self.a.G.node[n]['xyz'][2])))
        #f.close()

>>>>>>> origin/petraDev
        # set up brain with graph properties
        self.c = mbo.brainObj()
        self.c.importAdjFile(assocMat, delimiter=delim, exclnodes=nodesToExclude)
        self.c.importSpatialInfo(spatialFile)

    def comparison(self):
        # set up dictionary to link nodes from probe data and graph
        # keys are the mri nodes and values are disctionaries containing two keys: 
        # key 1= allen, value= (n=id of closest allen node, d=distance to closest allen node)
        # key 2= mri, value= (n=id of closest other mri node, d=distance to closest mri node)
        nodeDictMRIs = {}
       
        for node in self.c.G.nodes():
            dOther = (None, 999.) # dummy length of 999
            dOwn = (None, 999.)
       
            for n in self.a.G.nodes():
                d = np.linalg.norm(np.array(self.c.G.node[node]['xyz'] - np.array(self.a.G.node[n]['xyz'])))
                if d < dOther[1]:
                    dOther = (n,d)
           
            for n in [v for v in self.c.G.nodes() if not v==node]:
                d = np.linalg.norm(np.array(self.c.G.node[node]['xyz'] - np.array(self.c.G.node[n]['xyz'])))
                if d < dOwn[1]:
                    dOwn = (n,d)
            nodeDictMRIs[node] = {"allen":dOther, "MRIs":dOwn}
       
        # set up dictionary to link nodes from probe data and graph
        nodeDictAllen = {}
        for node in self.a.G.nodes():
            dOther = (None, 999.)
            dOwn = (None, 999.)
           
            for n in self.c.G.nodes():
                d = np.linalg.norm(np.array(self.a.G.node[node]['xyz'] - np.array(self.c.G.node[n]['xyz'])))
                if d < dOther[1]:
                    dOther = (n,d)
           
            for n in [v for v in self.a.G.nodes() if not v==node]:
                d = np.linalg.norm(np.array(self.a.G.node[node]['xyz'] - np.array(self.a.G.node[n]['xyz'])))
                if d < dOwn[1]:
                    dOwn = (n,d)
            nodeDictAllen[node] = {"allen":dOwn, "MRIs":dOther}
       
        nodePairs = []
        # for each MRI node
        for node in nodeDictMRIs.keys():
            # find closest allen node 'n'
            n = nodeDictMRIs[node]['allen'][0]
            self.c.G.node[node]['pair'] = n
            self.a.G.node[n]['pair'] = node
            nodePairs.append((node,n))
            # if there is no other MRI node closer to the current MRI region 
            # if nodeDictMRIs[node]['allen'][1] < nodeDictMRIs[node]['MRIs'][1]:
            # if there is also no other MRI node closer to this allen region then match
            #     n = nodeDictMRIs[node]['allen'][0]
            #     if nodeDictAllen[n]['MRIs'][0] == node:
            #         self.c.G.node[node]['pair'] = n
            #         self.a.G.node[n]['pair'] = node
            #         nodePairs.append((node,n))
            #     else:
            # if there is another MRI node closer to this allen region then delete current regions (and do not match it)
            #         self.c.G.remove_node(node)
            # else:
            #     self.c.G.remove_node(node)
       
        for node in self.a.G.nodes():
            if not 'pair' in self.a.G.node[node].keys():
                self.a.G.remove_node(node)

    def comparisonAveraged(self):
        """
        This function should generate sets of nodes in the imaging data associated
        with single nodes in the Allen data, ie all the closes imaging data nodes will
        be associated with any specific Allen node.
        """
        for n in self.a.G.nodes():
            self.a.G.node[n]['pairNodes'] = []
        
        # iterate through imaging nodes to find closes Allen node
        for node in self.c.G.nodes():
            dOther = (None, 999.) # dummy length of 999
       
            for n in self.a.G.nodes():
                d = np.linalg.norm(np.array(self.c.G.node[node]['xyz'] - np.array(self.a.G.node[n]['xyz'])))
                if d < dOther[1]:
                    dOther = (n,d)
                    
            self.a.G.node[dOther[0]]['pairNodes'].append(node)
       
        for node in self.a.G.nodes():
            if not self.a.G.node[node]['pairNodes']:
                self.a.G.remove_node(node)

    def probeData(self, probeNumbers=[]):
        for subj in self.subjList:
            # import probe data
            f = open(path.join(subj, self.maFile), "rb")
            reader = csv.DictReader(f, delimiter=",",
                                    fieldnames=self.headers[subj],
                                    quotechar='"')
            for l in reader:
                probe = l['probe']
                if probe in probeNumbers:
                    # assign probe values to sample numbers
                    for node in self.a.G.nodes():
                        if not probe in self.a.G.node[node].keys():
                            self.a.G.node[node][probe] = {}
                           
                        if str(node) in l.keys():
                            self.a.G.node[node][probe][subj] = l[str(node)]
            f.close()
            del(reader)
        # self.a.G.nodes is a dict containing every UNIQUE structure id (across all subjects)      
        for n in self.a.G.nodes():
            for probe in probeNumbers:
                self.a.G.node[n][probe] = np.mean([float(v) for v in self.a.G.node[n][probe].values()])
               
    def writeXMatrix(self, outFile="Xmatrix.csv", probeNumbers=None):
        # get all probes if otherwise unspecified
        if not probeNumbers:
            f = open(path.join(self.subjList[0], self.probeFile))
            reader = csv.DictReader(f, delimiter=",", quotechar='"')
            probeNumbers = [l['probe_id'] for l in reader]
            del(reader)
            f.close()  
   
        # set up out file
        out = open(outFile, "wb")
        headers = ["Gene"]
        headers.extend([str(v) for v in self.c.G.nodes()])
        writer = csv.DictWriter(out, fieldnames = headers, delimiter=" ")
        writer.writeheader()
       
        # set up matrix
        x = len(self.subjList)
        y = len(probeNumbers)
        z = len(self.c.G.nodes())
        print(x,y,z)
        probeMat = np.memmap("tempMat.txt",
                             dtype="float64",
                             mode="w+",
                             shape=(x,y,z))
                             
        # get the corresponding node names in the MRI graph
        # cNodes is a dict whose keys are all the MRI nodes and values are the matched alen nodes
        #### PV modified line below which constructed cNodes by looping through allen nodes
        # but with PV's lax matching criteria several mri nodes can be matched to same allen node
        # the mri pair of these allen nodes gets overwritten in self.a.G.nodes and so not all mri nodes will appear 
        # as pairs of allen nodes in this dict... need to look up pairs in self.c.G.nodes instead, where
        # each mri node is matched to an allen region
        # cNodes = {str(self.a.G.node[v]['pair']):v for v in self.a.G.nodes()}
        
        cNodes = {str(v):self.c.G.node[v]['pair'] for v in self.c.G.nodes()}

        # set up gene list
        geneFlag = True
        pFile = open(path.join(self.subjList[0], self.probeFile))
        pReader = csv.DictReader(pFile, delimiter=",", quotechar='"')
        pDict = {l['probe_id']:l['gene_symbol'] for l in pReader}
        geneList = pDict.values()
        set(geneList)
        geneList = {gene:[] for gene in geneList}
       


        # assign values to matrix
        for x,subj in enumerate(self.subjList):
            print(str(subj))
            print('\n')
            # Generate custom fieldnames list for DictReader which doesn't rely on structure_id
            # *************************************
            fieldnames_pv = ['probe']
            myNodeDict = {}
            tempHeaders = self.headers[subj]
            tempHeaders.remove('probe')

            for p,q in enumerate(self.headers[subj]):
                myNodeDict[p] = q
                fieldnames_pv.append(str(p))   #####
            # *************************************


            # import probe data
            f = open(path.join(subj, self.maFile), "rb")
            reader = csv.DictReader(f, delimiter=",",
                                    fieldnames=fieldnames_pv,
                                    quotechar='"')
            y = 0
            for l in reader:
                probe = l['probe']
                if probe in probeNumbers:


                    # assign probe values to sample numbers
                    for z,cNode in enumerate(self.c.G.nodes()):
                        aNode = cNodes[str(cNode)]
                        # *************************************
                        # Find structure_acronym corresponding to the matched allen node
                        acronym = self.a.G.node[aNode]['structure_acronym']
                        # Initialise list for summing expression values for allen nodes with same structure_acronym
                        totalExpression = []
                        # Loop over allen nodes to find all those with the correct acronym for the current MRI node
                        # and add their expression values to the list for averaging
                        for ID, struct_ac in myNodeDict.iteritems():
                            if struct_ac == acronym:
                                # print(ID, struct_ac, l[str(ID)])
                                # print('\n')
                                # if l[str(ID)]:
                                totalExpression.append(float(l[str(ID)]))

                        if len(totalExpression) > 0:       #PVPVPVPVPVPVPVPVPVPVPVPVPVPVPV   
                            # Get average expression value for all allen nodes with this structure_acronym
                            meanExpression = sum(totalExpression)/float(len(totalExpression))
                            # if str(ID) in l.keys():      #PVPVPVPVPVPVPVPVPVPVPVPVPVPVPV
                            probeMat[x,y,z] = float(meanExpression) # NOTE: pv replaced l[str(aNode)] by meanExpression
                    if geneFlag:
                        geneList[pDict[probe]].append(y)
                    y+=1
            f.close()
            del(reader)

            # normalise expression levels for each probe within subject
            for y in range(probeMat.shape[1]):
                # create a masked array removing the 0. values
                subjMat = np.ma.array(probeMat[x,y,:],
                                      mask=probeMat[x,y,:]==0.,
                                      dtype="float64")

                if len(subjMat[subjMat.mask]>1):
                    subjMat = (subjMat - np.mean(subjMat)) / np.std(subjMat)
                else:
                    subjMat = subjMat - np.mean(subjMat)
                probeMat[x,y,:] = subjMat
            geneFlag=False
       
        # collapse across subjects and probes by gene
        geneNames = geneList.keys()
        geneNames.sort() # sort in to alphabetical order
       
        for g,gene in enumerate(geneNames):
            if (geneList[gene]):
                x = probeMat.shape[2] # number of nodes
                y = probeMat.shape[0]*len(geneList[gene]) # subjects * probes
                               
                geneMat = np.zeros(shape=(x,y), dtype="float64")
               
                for n,p in enumerate(geneList[gene]):
                    for s,subj in enumerate(self.subjList):
                        geneMat[:,n*len(self.subjList)+s] = probeMat[s,p,:]
                   
                geneMat = np.ma.array(geneMat, mask=geneMat==0.)
               
                self.geneMat = geneMat
                meanGene = np.mean(geneMat, axis=1)
               
                outDict = dict(zip([str(v) for v in self.c.G.nodes()], ["{:10.20f}".format(v) for v in meanGene]))
                outDict["Gene"] = gene
                writer.writerow(outDict)
       
        self.geneList = geneList
        self.probeMat = probeMat
        out.close()
   
    def writeYMatrixGroup(self, metricDict, subj="Control", outFile="YmatrixGroup.csv"):
        '''
        Collates metrics in to a matrix for use in partial least squares analysis.
        Note, the metricDict contains the metric name as a key and filename as
        the value. Takes group level measures
        '''
        out = open(outFile, "wb")
        headers = ["Metric"]
        headers.extend([str(v) for v in self.c.G.nodes()])
        writer = csv.DictWriter(out, fieldnames=headers)
        writer.writeheader()
       
        # iterate through the metrics
        for m in metricDict.keys():
            f = open(path.join(subj, metricDict[m]), "r")
            reader = csv.DictReader(f, delimiter=" ")
            l = reader.next()
           
            # remove non-numeric keys
            for v in l.keys():
                try:
                    int(v)
                except:
                    del(l[v])

            mDict = {v:l[v] for v in l.keys() if int(v) in self.c.G.nodes()}
            f.close()
           
            # normalise within metric
            meanMetric = np.mean([float(v) for v in mDict.values()])
            sdMetric = np.std([float(v) for v in mDict.values()])

            mDict = {str(v):(float(mDict[str(v)])-meanMetric)/sdMetric for v in mDict.keys()}
           
            mDict["Metric"] = m
           
            writer.writerow(mDict)
           
    def writeYMatrixIndividuals(self, metricDict, subjList, outFile="YmatrixInd.csv"):
        '''
        Collates metrics in to a matrix for use in partial least squares analysis.
        Note, the metricDict contains the metric name as a key and filename as
        the value. Takes metrics for individual subjects defined in the subject list.
        '''
        out = open(outFile, "wb")
        headers = ["Metric", "Subject"]
        headers.extend([str(v) for v in self.c.G.nodes()])
        writer = csv.DictWriter(out, fieldnames=headers)
        writer.writeheader()
       
        # iterate through the metrics
        for m in metricDict.keys():
            for subj in subjList:            
                f = open(path.join(subj, metricDict[m]), "r")
                reader = csv.DictReader(f, delimiter=" ")
                l = reader.next()
               
                # remove non-numeric keys
                for v in l.keys():
                    try:
                        int(v)
                    except:
                        del(l[v])
   
                mDict = {v:l[v] for v in l.keys() if int(v) in self.c.G.nodes()}
                f.close()
               
                # normalise within metric
                meanMetric = np.mean([float(v) for v in mDict.values()])
                sdMetric = np.std([float(v) for v in mDict.values()])
   
                mDict = {str(v):(float(mDict[str(v)])-meanMetric)/sdMetric for v in mDict.keys()}
               
                mDict["Metric"] = m
                mDict["Subject"] = subj
               
                writer.writerow(mDict)
